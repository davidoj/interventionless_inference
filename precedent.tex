%!TEX root = main.tex

\section[Precedented options]{Inferring consequences when options have precedent}\label{sec:precedent}

We have suggested that conditionally independent and identical responses is usually an unreasonably strong assumption for a decision maker to make, on the grounds that it implies overly strong interchangeability properties between different datasets. One way to get around this objection is to suppose that conditionally independent and identical responses are shared by pairs $(\RV{E}_i,\RV{X}_{i})$ where the $\RV{E}_i$ are in fact latent variables. In this case, the assumption would still assert that infinite $(\RV{E}_i,\RV{X}_{i})$ sequences arising from observation would be interchangeable with infinite $(\RV{E}_j,\RV{X}_{j})$ sequences arising as consequences of actions, but because the $\RV{E}_i$ are never observed these interchanges do not imply that we would use the same model for different experiments.

To simplify the presentation, we will consider a specific kind of decision model featuring long sequence of exchangeable observations indexed by natural numbers that are unresponsive to the decision maker's choice and ``one more'' variable representing the ``consequences of action'' indexed by the special character $c$ that may be responsible ot the decision maker's choice. That is, we have $(\RV{X}_i)_{i\in \mathbb{N}}$ unresponsive to the decision maker and $(\RV{X}_c)$ responsive to the decision maker. Call this setup a ``see-do model''.

\begin{definition}[See-do model]
A see-do model is an decision model $(\prob{P}_\cdot,\Omega,C)$ along with a sequence of variables $\RV{X}_{\mathbb{N}\cup\{c\}}$ where $\RV{X}_{\mathbb{N}}\CI^e_{\prob{P}_\cdot} \mathrm{id}_C$. Variables indexed with $i\in \mathbb{N}$ are referred to as \emph{observations} and variables indexed with the special index $c$ are referred to as \emph{consequences}. We specify a see-do model with the shorthand $(\prob{P}_\cdot,\RV{X}_{\mathbb{N}\cup\{c\}})$.
\end{definition}

In this section, we will consider the following kind of ``standard'' see-do model: we have some observed variables $(\RV{X},\RV{Y},\RV{Z})$ and an unobserved variable $\RV{E}$ such that the observation pairs $(\RV{Z}_{i},(\RV{E}_i,\RV{X}_i,\RV{Y}_i))_{i\in \mathbb{N}}$ share conditionally independent and identical responses. Typically, this might be because we assume observations are exchangeable, but we also allow for cases where $\RV{Z}_i$ is not exchangeable -- for example, perhaps it is a time variable which monotonically increases. We also assume that the pairs $(\RV{E}_i,(\RV{X}_i,\RV{Y}_i))_{i\in\mathbb{N}\cup\{c\}}$ share conditionally independent and identical responses for all indices.

Recall that in Section \ref{sec:evaluating_decisions} we suggested that many systems might exhibit (probabilistically) regular input-output behaviours, but where we might not know or observe the right ``inputs''. The assumption that the pairs $(\RV{E}_i,(\RV{X}_i,\RV{Y}_i))_{i\in\mathbb{N}\cup\{c\}}$ share conditionally indpendent and identical responses can be viewed as a formalisation of this intuition; there is some unknown and unobserved state $\RV{E}_i$ which $\RV{X}_i$ and $\RV{Y}_i$ respond to in a regular manner no matter what else is happening.

Note that we make no assumptions about the distribution of $\RV{Z}_c$.

\begin{definition}[Latent CIIR see-do model]\label{def:lciirm}
A \emph{latent CIIR see-do model} is a see-do model $(\prob{P}_\cdot,(\RV{E}_i,\RV{Z}_{i},\RV{X}_i,\RV{Y}_i)_{i\in \mathbb{N}\cup\{c\}})$ such that the observation pairs $(\RV{Z}_{i},(\RV{E}_i,\RV{X}_i,\RV{Y}_i))_{i\in \mathbb{N}}$ share conditionally independent and identical responses and the pairs $(\RV{E}_i,(\RV{X}_i,\RV{Y}_i))_{i\in\mathbb{N}\cup\{c\}}$ also share conditionally independent and identical responses. We say the $\RV{E}_i$s are ``latent'' variables, which informally means that we typically do not get to observe them. We adopt the convention that the directing random conditional of $(\prob{P}_\cdot,\RV{Z}_{\mathbb{N}},(\RV{E}_i,\RV{X}_i,\RV{Y}_i)_{i\in \mathbb{N}})$.
\end{definition}

We can take any see-do model $(\prob{P}_\cdot,\RV{X}_{\mathbb{N}\cup\{c\}})$ with exchangeable observations and turn it into a latent CIIR see-do model by setting $\RV{Z}_i=*$ and $\RV{E}_i=(\RV{X}_i,\RV{Y}_i)$. This trivial construction typically isn't very helpful, though. One particular feature we might want is for a latent CIIR model to express the fact that ``things we can do have been done before''; that is, any setting of the unobserved state $\RV{E}_c$ that our actions might yield has positive probability in the observed data. Example \ref{ex:construction_latent_set} illustrates model constructions with and without this property.

\begin{example}\label{ex:construction_latent_set}
Suppose we have a see-do model $(\prob{P}_\cdot, \RV{X}_{\mathbb{N}\cup\{c\}})$ where each $\RV{X}_i$ takes values in a binary set, and the control we can exert is to choose either $\prob{P}_{0}^{\RV{X}_c} = \frac{1}{4}\delta_0 + \frac{3}{4}\delta_1$ or $\prob{P}_{1}^{\RV{X}-c} = \frac{1}{2}\delta_0 + \frac{1}{2}\delta_1$, independent of all other observations. Suppose further that for $i\in \mathbb{N}$, $\prob{P}_C^{\RV{X}_i}=\frac{3}{4}\delta_0 + \frac{1}{4}\delta_1$ independent of all other observations. Then we can consider this model to be IO contractible with latent binary inputs $\RV{E}_i$ such that
\begin{align}
	\prob{P}_\alpha^{\RV{X}_i|\RV{E}_i}(\cdot|e) &= \delta_e
\end{align}

This is not the only way to construct such a model. We could instead choose latent binary inputs $\RV{E}_i'$ such that
\begin{align}
	\prob{P}_\alpha^{\RV{X}_i|\RV{E}_i'}(\cdot|e) &= \begin{cases}
		\frac{3}{4}\delta_0 + \frac{1}{4}\delta_1 & e=0 \\
		\frac{1}{4}\delta_0 + \frac{3}{4}\delta_1 & e=1
	\end{cases}
\end{align}

On the other hand, the choice $\RV{E}_i^{\prime\prime}$ with
\begin{align}
	\prob{P}_\alpha^{\RV{X}_i|\RV{E}_i''}(\cdot|e) &= \begin{cases}
		\frac{1}{2}\delta_0 + \frac{1}{2}\delta_1 & e=0 \\
		\frac{1}{4}\delta_0 + \frac{3}{4}\delta_1 & e=1
	\end{cases}
\end{align}
cannot be latent binary inputs for a conditionally independent and identical response model, as the observational distribution cannot be written as any convex combination of $\prob{P}_\alpha^{\RV{X}_i|\RV{E}_i''}(\cdot|0)$ and $\prob{P}_\alpha^{\RV{X}_i|\RV{E}_i''}(\cdot|1)$.
\end{example}

In the first construction in Example \ref{ex:construction_latent_set}, but not the following two, we have $\prob{P}_C^{\RV{E}_i} \gg \prob{P}_\alpha^{\RV{E}_c}$ for all $\alpha$. We say under this construction the options have \emph{precedent}; they have, in a sense, ``been done before''. The assumption of precedent by itself has some implications -- for example, if a decision maker considers precedent a reasonable assumption and they have access to a lot of data, they they should not expect any of their actions to lead to consequences that have never appeared before in the observational data. In Theorem \ref{th:latent_to_observable}, we will make use a stronger version of this assumption where the conditional distribution over $\RV{E}_i$ is different for each value of $\RV{Z}_i$, which leads to stronger conclusions. We will discuss the plausibility of the stronger assumption afterwards.

Theorem \ref{th:latent_to_observable} is motivated by the following example:

\begin{example}\label{ex:doctor_precedent}
Suppose a decision maker collects data about a group of peope who have variously engaged the services of dietiticians, sporting coaches, general practitioners, bariatric surgeons and none of the above, with practitioner choice recorded under the variable $\RV{Z}_i$. The decision maker has also collected data on each person's body mass index $\RV{X}_i$ at the beginning of the study and followed mortality outcomes $\RV{Y}_i$ for a considerable period of time. A decision maker is reviewing this data, and in particular is wondering if steps they take to manage their weight $\RV{X}_c$ are likely to improve their own mortality prospects $\RV{Y}_c$.

Our decision maker presumes that each group of people $\RV{Z}_i$ has, in aggregate, different strategies for pursuing weight management and different contextual reasons for doing so (though, for the sake of this example, we suppose that the decision maker doesn't collect data on any of these facts). Because of this variation, the decison maker reasons, people in these different groups with different levels of body mass index should see different mortality results \emph{if, conditional on body mass index, the different circumstances and management strategies actually lead to different results}. Conversely, if there is \emph{no} variation in results for these different groups of people, then it would appear that, at least with regard to mortality, the eventual body mass index achieved is apparently the \emph{only} important feature of any management plan.

This inference might fail if, for any reason, the variation in treatment plans and contexts between the different groups of people surveyed masks the variation in their effects. For example, if all groups of people overwhelmingly choose to pursue diet changes in the end and other dimensions of variation are simply not very important to the outcome, then their results will not reveal any variation in mortality outcomes due to different treatment strategies. Alternatively, it might be the case that everybody is making choices that achieve nearly optimal mortality prospects given their unobserved context and that the best achievable mortality outcomes are approximately the same for each person's achievable level of body mass index. In this case there may still be substantial variation in outcomes from different weight management strategies, but it is masked by the fact that everyone is making near-optimal choices.

If the decision maker finds that $\RV{Y}_i$ is not independent of $\RV{Z}_i$ given $\RV{X}_i$, they may also consider whether $\RV{Y}_i$ is independent of $\RV{Z}_i$ given $(\RV{V}_i,\RV{X}_i)$ for some set of covariates $\RV{V}_i$.
\end{example}

Theorem \ref{th:latent_to_observable} establishes formal conditions for the informal deduction described in Example \ref{ex:doctor_precedent}. We assume that all variables of interest are discrete, and make use of an alternative notation for discrete conditional probabilities.

\begin{definition}[Index notation for discrete conditionals]
Given a joint probability distribution $\mu^{\RV{XY}}$ with $\RV{X}$ and $\RV{Y}$ discrete, let $\mu^y_x:=\mu^{\RV{Y}|\RV{X}}(\{y\}|x)$ and $\mu^Y_X:= (x,y)\mapsto \mu^y_x$
\end{definition}

The key assumption for Theorem \ref{th:latent_to_observable} is an assumption we call \emph{diverse precedent}. It's a rather complicated assumption. It imposes a domination condition that requires (roughly speaking) that the distribution of the latent input $\RV{E}_i$ given event $\RV{Z}_i=z$ almost surely dominates the distribution induced by any option we can choose (as in the discussion of precedent above) \emph{and} is almost surely ``diverse'' for different values of $\RV{Z}_i$.

\begin{definition}[Diverse precedent]\label{def:diverse_precedent}
Given a latent CIIR see-do model $(\prob{P}_\cdot,(\RV{E}_i,\RV{X}_i,\RV{Y}_i,\RV{Z}_i)_{i\in\mathbb{N}\cup\{c\}})$ with $E,X,Y$ and $Z$ all discrete, recall $\RV{G}$ is the directing random conditional of $(\prob{P}_\cdot,\RV{Z}_{\mathbb{N}},(\RV{E}_i,\RV{X}_i,\RV{Y}_i)_{i\in \mathbb{N}})$. 

We say that the options $C$ have \emph{diverse precedent} with respect to $(\prob{P}_\cdot,(\RV{E}_i,\RV{X}_i,\RV{Y}_i,\RV{Z}_i)_{i\in\mathbb{N}\cup\{c\}})$ if $\prob{P}_\cdot$ satisfies the diversity condition:
\begin{align}
    \prob{P}_{\alpha}^{\RV{G}^{EX}_{Z}|\RV{G}^{Y}_{EXZ}}(\cdot|g^{Y}_{EXZ}) &\ll U_{\Delta(E)}& \forall \alpha, z, \prob{P}_\alpha-\text{almost all }g^{Y}_{EXZ}\label{eqApp:lebesgue_dom}
\end{align}
as well as the precedent condition:
\begin{align}
    \prob{P}_\alpha^{\RV{E}_c|\RV{G}} &\ll \sum_{z\in Z}\prob{P}_\alpha^{\RV{E}_i|\RV{G}}(\cdot|g)&\prob{P}_\alpha-\text{almost all }g
\end{align}
Where $U_{\Delta(E)}$ is the uniform measure on the $|E-1|$ simplex of discrete probability distributions with $|E|$ outcomes.
\end{definition}

For Theorem \ref{th:latent_to_observable}, we assume that on the basis of observations we condition the probability on some event $I$ (in particular, we are interested in the case where $I$ is the event that a certain conditional independence holds).

\begin{theorem}[Latent to observable IO contractibility]\label{th:latent_to_observable}
Given a latent CIIR see-do model $(\prob{P}_\cdot,(\RV{E}_i,\RV{X}_i,\RV{Y}_i,\RV{Z}_i)_{i\in\mathbb{N}\cup\{c\}})$ with $E,X,Y$ and $Z$ all discrete, recall $\RV{G}$ is the directing random conditional of $(\prob{P}_\cdot,\RV{Z}_{\mathbb{N}},(\RV{E}_i,\RV{X}_i,\RV{Y}_i)_{i\in \mathbb{N}})$.

Let $I\subset \Delta(Y)^{XZ}$ be the event $\RV{G}^Y_{Xz}=\RV{G}^Y_{Xz'}$ for all $z,z'\in Z$; i.e. the event that $\RV{Y}_i$ is independent of $\RV{Z}_i$ conditional on $\RV{X}_i$ and $\RV{G}^Y_{XZ}$. Define $\prob{Q}_\alpha\in \Delta(\Omega)$ to be the probability measure such that, for all $A\in \sigalg{F}$
\begin{align}
\prob{Q}_\alpha(A) := \prob{P}_\alpha^{\mathrm{id}_\Omega|\mathds{1}_I\circ \RV{G}}(A|1)
\end{align}
i.e. $\prob{Q}_\alpha$ is $\prob{P}_\alpha$ conditioned on $\RV{G}^Y_{XZ}\in I$, so $\RV{Y}_i\CI^e_{\prob{Q}_\cdot} \RV{Z}_i|(\RV{X}_i,\mathrm{id}_C)$.

If the options $C$ have diverse precedent with respect to $(\prob{Q}_\cdot,(\RV{E}_i,\RV{X}_i,\RV{Y}_i,\RV{Z}_i)_{i\in\mathbb{N}\cup\{c\}})$, then the model $(\prob{Q}_\cdot,\RV{X},\RV{Y})$ features conditionally independent and identical responses $(\RV{X}_i,\RV{Y}_i)$.
\end{theorem}

\begin{proof}
We show that the assumption of conditional independence imposes a polynomial constraint on $\RV{G}^d_z$ which is nontrivial unless $\RV{Y}_i\CI^e (\RV{Z}_i,\RV{E}_i,\text{id}_C)|(\RV{X}_i,\RV{H})$, and hence the solution set $S$ for this constraint has measure 0 when this conditional independence does not hold.

Full proof in Appendix \ref{sec:proof_precedent}.
\end{proof}

\section[Independent mechanisms]{Diversity, interventional models and the principle of independent causal mechanisms}

In this section we will present an informal argument that connects the principal of \emph{diversity} (Def. \ref{def:diverse_precedent}) to a particular family of structural interventional models via the principle of independent causal mechanisms.

As we have already mentioned ``precedent'' part of Definition \ref{def:diverse_precedent} can be intepreted as the assumption that whatever the decision maker can do has been done before. It is more likely to be acceptable when the actions the decision maker is considering are common -- such as controlling body mass index by adopting a widely known diet -- and less likely to be acceptable when the decision maker is considering uncommon actions like controlling body mass index by removing limbs. It is less obvious what considerations might lead one to accept or reject the diversity condition.

To better understand this, we note that Theorem \ref{th:latent_to_observable} can be informally summarised as follows:
\begin{itemize}
	\item If $\RV{Y}_i\CI^e_\prob{Q} \RV{Z}_i |(\RV{X}_i,\RV{G},\mathrm{id}_C)$ then we must either have ``alignment'' between $\RV{G}^{XE}_Z$ and $\RV{G}^{Y}_{EXZ}$ or we also have $\RV{Y}_i\CI^e_\prob{Q} \RV{E}_i |(\RV{X}_i,\RV{G},\mathrm{id}_C)$
	\item If we assume diversity of $\RV{G}^{XE}_Z$ conditioned on $\RV{G}^{Y}_{EXZ}$ -- i.e. we rule out ``alignment'' -- then we must conclude $\RV{Y}_i\CI^e_\prob{Q} \RV{E}_i |(\RV{X}_i,\RV{G},\mathrm{id}_C)$
\end{itemize}

What we mean by ``alignment'' here is that $\RV{G}^{XE}_Z$ is restricted to some particular set of Lebesgue measure 0 conditioned on $\RV{G}^{Y}_{EXZ}$ in order to yield the independence $\RV{Y}_i\CI^e_\prob{Q} \RV{Z}_i |(\RV{X}_i,\RV{G},\mathrm{id}_C)$. ``Alignment'' of this form might seem like it would usually be unlikely, but this is not necessarily so. However, there are several reasons not to assume that the diversity condition is satisfied in general. 

First, we require diversity to be satisfied \emph{after} observing $\RV{Y}_i\CI^e_\prob{Q} \RV{Z}_i |(\RV{X}_i,\RV{G},\mathrm{id}_C)$. If we accept diversity in this context, then we conclude $\RV{Y}_i\CI^e_\prob{Q} \RV{E}_i |(\RV{X}_i, \RV{Z}_i, \RV{G},\mathrm{id}_C)$, which is \emph{also} a Lebesgue measure 0 event with respect to $\Delta(Y)^{EXZ}$. Thus it's not enough to assume that violations of diversity are unlikely in general -- we have to assume that they are less likely than the conditional independence $\RV{Y}_i\CI^e_\prob{Q} \RV{E}_i |(\RV{X}_i, \RV{Z}_i, \RV{G},\mathrm{id}_C)$.

Second, some violations of diversity may be relatively plausible. For example, the independence $\RV{E}_i\CI^e_\prob{Q} \RV{Z}_i |(\RV{G},\mathrm{id}_C)$ is a violation of diversity, but the unconditional independence of two variables is not, in general, an implausible event.

Third, the \emph{principal of independent causal mechanisms} (ICM) offers another possible way for the assumption of diversity to fail\citep{lemeire_replacing_2013,peters_elements_2017}. ICM is an informal principle that posits conditionals like $\RV{G}^{XE}_Z$ and $\RV{G}^{Y}_{EXZ}$ will be ``independent'' or ``unaligned'' under structural causal assumptions that identify both of these conditionals as ``causal mechanisms''. Conversely, it is argued (for example in \citet[Ch. ~2]{peters_elements_2017}) that conditionals that do not correspond to ``causal mechanisms'' may exhibit ``alignment'' of the kind we have discussed here.

The first of these reasons is a general caution against assuming diversity too readily in any situation. The second and third are two different ways that the diversity condition could fail. In fact, both of these failures of diversity can be illustrated with a particular family of graphical causal models.

\subsection{Graphical models and causal mechanisms}

A graphical causal model is defined in \citet[Ch. ~1]{pearl_causality:_2009} as a large collection of \emph{interventional conditionals} which can be compactly encoded with a probability distribution over a collection of variables together with a graph associated with these variables (see Definition \ref{def:vga}). We will consider a slightly different variety of graphical model; we will consider a \emph{graphical ciir model} to be a directed acyclic graph $\mathcal{G}$ associated with a latent CIIR model (Definition \ref{def:lciirm}) instead of a collection of interventional conditionals.

\begin{definition}[Graphical CIIR model]
A graphical CIIR model is a latent CIIR model $(\prob{P}_\cdot,(\RV{E}_i,\RV{Z}_{i},\RV{X}_i,\RV{Y}_i)_{i\in \mathbb{N}\cup\{c\}})$ along with a collection of directed acyclic graphs $\mathscr{G}:=\{\mathcal{G}_i|i\in A\subset\mathbb{N}\}$ associated with $(\RV{E}_c, \RV{Z}_c,\RV{X}_c,\RV{Y}_c)$.
\end{definition}

A \emph{causal mechanism} in a graphical CIIR model is a conditional distribution associated with a parental set in the associated graph $\mathcal{G}$.

\begin{definition}[Causal mechanism]
Given a CIIR model $(\prob{P}_\cdot,(\RV{E}_i,\RV{Z}_{i},\RV{X}_i,\RV{Y}_i)_{i\in \mathbb{N}\cup\{c\}})$ along with an associated graph $\mathcal{G}$, a \emph{causal mechanism} is a conditional distribution $\RV{G}^{V}_{\mathrm{Pa}_{\mathcal{G}}(\RV{V})}$ for any $V\in \{\RV{E}_c,\RV{Z}_c,\RV{X}_c,\RV{Y}_c\}$.
\end{definition}

We hold that every graph in a graphical CIIR model is associated with an event. We can condition on the event associated with $\mathcal{G}_i$ to yield the model that would obtain ``if we knew $\mathcal{G}_i$ were the correct caual graph''. We require that the model conditioned on a graph $\mathcal{G}_i$ is \emph{compatible} with this graph -- which reflects the common prescription that a probability distribution should be \emph{compatible} with an associated causal graph $\mathcal{G}$\citet[Ch. ~1]{pearl_causality:_2009} -- and we \emph{also} require that, after conditioning on a graph, the causal mechanisms in the graph are \emph{mutually diverse}. This is a formalisation of the principal of independent causal mechanisms. We treat graphs as conditioning events to reflect the fact that we do not necessarily know \emph{a priori} whether or not this compatibility holds for any given graph.

\begin{definition}[Conditioning on a graph]
We will assume that each graph $\mathcal{G}_i\in \mathscr{G}$ describes a conditioning event for the associated CIIR model $(\prob{P}_\cdot,(\RV{E}_i,\RV{Z}_{i},\RV{X}_i,\RV{Y}_i)_{i\in \mathbb{N}\cup\{c\}})$ such that, letting $\prob{P}_{\cdot,i}$ be the result of conditioning $\prob{P}_\cdot$ on the event associated with $\mathcal{G}_i$, we have:
\begin{enumerate}
	\item $V_j\perp_{\mathcal{G}} V_k|\RV{V}_l$ for $V_j,V_k,V_l\in \{E_c,Z_c,X_c,Y_c\}$ implies $\RV{V}_j\CI^e_{\prob{P}_{\cdot,i}} \RV{V}_k |(\RV{V}_l,\RV{G},\mathrm{Id}_C)$
	\item $\prob{P}_{\alpha,i}^{\RV{G}^{V_j}_{\mathrm{Pa}_{\mathcal{G}_i}(V_j)}|(\RV{G}^{V_k}_{\mathrm{Pa}_{\mathcal{G}_i}}(V_k))_{k\neq j}}(\cdot|(g^{V_k}_{\mathrm{Pa}_{\mathcal{G}_i}(V_k)})_{k\neq j}) \ll U_{\Delta(V_j)}$ for all $\alpha, z$ and $\prob{P}_\alpha$-almost all $(g^{V_k}_{\mathrm{Pa}_{\mathcal{G}_i}(V_k)})_{k\neq j}$
\end{enumerate}
\end{definition}



\begin{example}[Using causal discovery to justify Theorem \ref{th:latent_to_observable}]
Suppose we have a latent CIIR see-do model $(\prob{P}_\cdot,(\RV{E}_i,\RV{X}_i,\RV{Y}_i,\RV{Z}_i)_{i\in\mathbb{N}\cup\{c\}})$, and we hypothesize that it may be associated with any of the following graphs:

\begin{align}
\mathscr{G}:=\tikzfig{diverse_precedent}\label{eq:diverse_precedent_graph1}
\end{align}

Here red edges correspond to edges that may or may not be present, and may be oriented in any direction. Of these graphs, only one is faithful to the conditional indepdendence $\RV{Y}_i\CI^e_\prob{Q} \RV{Z}_i |(\RV{X}_i,\RV{G},\mathrm{id}_C)$, yielding the graph

\begin{align}
\mathcal{G}=\tikzfig{diverse_precedent_afterindep}
\end{align}
We note in this graph that $\mathrm{Pa}_{\mathcal{G}}(\RV{E},\RV{X})=\RV{Z}$ and $\mathrm{Pa}_{\mathcal{G}}(\RV{Y})=\RV{X}$
\end{example}

, a ``causal mechanism'' is a conditional distribution $\RV{G}^{X}_{\mathrm{Pa}_{\mathcal{G}}(X)}$.

\emph{Causal discovery} refers to a variety of strategies that aim to infer a causal structure from a set of observations. A common approach to causal discovery is to learn the causal structures that are faithful to the conditional independence structure of the observed data. We can use this approach to causal discovery to motivate the assumption of diversity as follows:
\begin{itemize}
	\item Begin with a set of possible causal structures $\mathscr{G}$
	\item ``Observe'' $\RV{Y}_i\CI^e_\prob{Q} \RV{Z}_i |(\RV{X}_i,\RV{G},\mathrm{id}_C)$ and retain the subset $\mathscr{G}'$ faithful to this conditional indepdenence
	\item Check whether $\RV{G}^{XE}_Z$ and $\RV{G}^{Y}_{EXZ}$ are independent causal mechanisms in the resulting set of causal structures
\end{itemize}





Then Diagram \eqref{eq:diverse_precedent_graph1} in combination with the principle of probabilistically independent causal mechanisms implies $\RV{G}^{E}_Z\CI^e_{\prob{P}} \RV{G}^{XY}_{EZ}|\mathrm{Id}_C$. By Theorem \ref{th:dp_from_int}, if we also assume that we have unconditional diversity of $\RV{G}^E_Z$ then we have diverse precedent. If, in addition, the observed data $\RV{T}$ enables us to conclude that $\RV{G}^Y_{xz}=\RV{G}^Y_{xz'}$ for all $z,z'$, then the conditions for Theorem \ref{th:latent_to_observable} are satisfied. We can therefore determine the effect of any action $\alpha$ on $\RV{Y}$ if we already know its effect on $\RV{X}$.

On the other hand, if we observe the same conditional independence but associate the model with the following graph:

\begin{align}
\tikzfig{diverse_precedent_miss}\label{eq:diverse_precedent_graph2}
\end{align}

We note that $\RV{G}^Y_{EXZ}$ is not identified by this graph as a ``causal mechanism'', and therefore the principle of probabilistically independent causal mechanisms implies neither $\RV{G}^{E}_{Z} \CI^e_{\prob{P}} \RV{G}^{XY}_{EZ}|\mathrm{Id}_C$ nor $\RV{G}^{X}_{{EZ}}\CI^e_{\prob{P}} \RV{G}^{\RV{Y}}_{\RV{EXZ}}|\mathrm{Id}_C$. Thus in this case we cannot in general conclude from $\RV{G}^Y_{xz}=\RV{G}^Y_{xz'}$ that the effect of any action $\alpha$ on $\RV{Y}$ can be determined by its effect on $\RV{X}$.

\subsubsection{Connection to causal discovery}

We will 

The principle of independent causal mechanisms is usually used to derive rules to test for causal directions \citet[Ch. ~4]{peters_elements_2017}. That is, rather than assuming causal directions and inferring independence of conditionals, this principle has typically been used to develop tests for independent conditionals in order to infer causal directions. For Theorem \ref{th:latent_to_observable}, we cannot test for all of the relevant independences because they involve the unobserved variable $\RV{E}$.

We might speculatively justify $\RV{E}_i$ as a causal parent of $\RV{X}_i$ and $\RV{Y}_i$ by referring to our original position that $\RV{E}_i$ represents some latent state which gives rise to probabilistically consistent response behaviour from $\RV{X}_i$ and $\RV{Y}_i$.

We also need to justify the assumption that $\RV{G}^{\RV{EZ}}$ is Lebesgue dominated. One way this might be violated is if a decision maker expects that $\RV{E}_i$ might be independent of $\RV{Z}_i$. In our original example this might occur if every doctor employs the same treatment plan (perhaps because there is a widely-agreed upon optimal plan) and has a similar mixture of patients. In that case, however, we would also observe the treatment $\RV{X}_i$ independent of $\RV{Z}_i$. 

\begin{align}
\tikzfig{e_z_independent}
\end{align}

In this graph, $\RV{G}_{\RV{E}}^{\RV{XY}}$ and $\RV{G}^{\RV{EXY}}_{\RV{Z}}$ are identified as independent causal mechanisms.

However we arrive at them, once we have the assumptions that $\RV{E}_i$ is a causal parent of $\RV{X}_i$ and $\RV{Y}_i$ and that $\RV{G}^{\RV{EZ}}$ is Lebesgue dominated, a sufficient additional condition for Theorem \ref{th:dp_from_int} is that $\RV{Z}_i$ is a causal parent of $(\RV{X}_i,\RV{Y}_i)$. As both $\RV{Z}_i$ and $(\RV{X}_i,\RV{Y}_i)$ are observed

In light of the problems associated with conditioning on a set of measure 0, it would be very useful to extend Theorem \ref{th:latent_to_observable} to an approximate result. Specifically, in the event $\RV{Y}_i$ is ``approximately independent'' of $\RV{Z}_i$ given $\RV{X}_i$ and $\RV{G}$, under what conditions is $\RV{Y}_i$ also approximately independent of $\RV{E}_i$ given $\RV{X}_i$ and $\RV{G}$? We speculate that a stronger version of the diverse precedent assumption will be necessary for such a theorem.

The diverse precedent assumption has a connection to the theory of causal graphical models. \citet{meek_strong_1995} justified the \emph{faithfulness} condition for causal graphs associated with discrete probability models on the assumption that the distribution of parameters of a distribution consistent with a particular causal graph are dominated by the Lebesgue measure. In this theory, we have a discrete set of hypotheses over causal structures that imply some conditional independences, and Lebesge-dominated priors over the directing measure after conditioning on any of the causal structure hypotheses and their associated independences. Applying similar reasoning to the present case, we posit an argument along these lines: if we have the independence $\RV{Y}_i\CI^e_{\prob{Q}}(\RV{E}_i,\RV{Z}_i)|(\RV{X}_i,\RV{G},\mathrm{id}_C)$ but not the independence $\RV{E}_i\CI^e_{\prob{Q}} \RV{Z}_i|(\RV{G},\mathrm{id}_C)$ and furthermore $\RV{Z}_i$ is an ancestor of $\RV{E}_i$ and $(\RV{E}_i,\RV{Z}_i)$ is an ancestor of $(\RV{X}_i,\RV{Y}_i)$ (so that $\RV{G}^E_Z$ and $\RV{G}^{XY}_{EZ}$ are associated with forward edges in the causal model) then the diverse precedent assumption may be supported. Note that it may be possible to rule out the independence $\RV{E}_i\CI^e_{\prob{Q}} \RV{Z}_i|(\RV{G},\mathrm{id}_C)$ on the basis of the non-independence of $\RV{Z}_i$ and $\RV{X}_i$.

Another relation between theory of causal graphical models and the present work may be found in the \emph{causal version of the principle of maximum entropy} \citep{sunCausalInferenceChoosing2006,janzingCausalVersionsMaximum2021}. The causal version of the principle of maximum entropy, in contrast to the standard version of the principle, suggests that priors be specified by sequentially maximising the entropy of a cause, then maximising the conditional entropy of the first effect given the cause and so forth. While the cited articles discuss using the principle of entropy maximisation to specify prior distributions over observed variables rather than distributions over directing conditionals, the same principle may perhaps be applied to the specification of priors over directing conditionals. We posit that the causal version of the prinicple of maximum entropy might support a similar line of argument: if $\RV{Y}_i\CI^e_{\prob{Q}}(\RV{E}_i,\RV{Z}_i)|(\RV{X}_i,\RV{G},\mathrm{id}_C)$ but not $\RV{E}_i\CI^e_{\prob{Q}} \RV{Z}_i|(\RV{G},\mathrm{id}_C)$ and $\RV{Z}_i$ is an ancestor of $\RV{E}_i$ and $(\RV{E}_i,\RV{Z}_i)$ is an ancestor of $(\RV{X}_i,\RV{Y}_i)$, then perhaps the causal version of the principle of maximum entropy offers some support for the diverse precedent assumption. Note that this (as well as the implication suggested in the previous paragraph) are highly speculative.

The causal version of the principle of maximum entropy is itself motivated by the general principle of \emph{independent causal mechanisms}. 


\section{Conclusion}

We employ a decision theoretic approach to causal inference to investigate two different approaches to answering the question ``how do my observations relate to the consequences of my choices?''. Firstly, we examined the assumption of conditionally independent and identical responses, and its equivalent form in IO contractibility, which we argued was often an unreasonable assumption and secondly, we examined an approach based on the principle of precedent, or the idea that the decision maker's options have been taken before, and some of their consequences observed. Our approach allows us to consider the question of what observations and consequences have in common independently from any prior knowledge the decision maker might have about how their choices influence outcomes -- neither Theorem \ref{th:ciid_rep_kernel} nor Theorem \ref{th:latent_to_observable} depend on any assumptions about a decision maker's prior knowledge of the effects of their different options (though the plausibility of the assumptions in both theorems may well depend on such prior knowledge).

The grand aim of this work is to facilitate causal inference in situations where a decision maker has relatively little causal knowledge at the outset. We think avoiding structured interventions in this setting is advantageous because we regard the question of whether an action is known in advance to influence a particular variable as substantially more transparent than the question of whether it is well modeled by a structured intervention (of any type) on that variable.

Nevertheless, this work leaves many open questions for causal inference in the low prior knowledge setting. We have argued that the assumptions required for Theorem \ref{th:ciid_rep_kernel} are unlikely to be compelling in many situations. While the diverse precedent assumption may be more broadly plausible, it is at this stage difficult to evaluate. Speculatively, it may be possible to make progress on this question by better understanding when structural assumptions support this conclusion, via for example the causal version of the principle of maximum entropy.

For practical purposes, a generalisation of Theorem \ref{th:latent_to_observable} to approximate independence is in order, and such a generalisation may also bring additional clarity to the diverse precedent assumption.

Despite these challenges, we are encouraged by a number of features of this work. Using decision making as a starting point for constructing models means that, at the outset, we are only making commitments a decision maker is likely to already be making if they want to apply a formal theory of decision making. The informal idea of precedent that underpins Theorem \ref{th:latent_to_observable} seems like a general principle that may be applicable in a broad range of data-driven decision making problems. Finally, the apparent connection between Theorem \ref{th:latent_to_observable} suggests that much of the work already done in the world of causal graphical models may be applicable to our alternative perspective. Causal inference under circumstances of limited prior knowledge presents many hard conceptual as well as practical problems, and our approach is a promising new avenue of investigation.