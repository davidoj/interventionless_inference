%!TEX root = main.tex

\section[Precedented options]{Inferring consequences when options have precedent}\label{sec:precedent}

We have suggested that conditionally independent and identical responses is usually an unreasonably strong assumption for a decision maker to make, on the grounds that it implies overly strong interchangeability properties between different datasets. One way to get around this objection is to suppose that conditionally independent and identical responses are shared by pairs $(\RV{E}_i,\RV{X}_{i})$ where the $\RV{E}_i$ are in fact latent variables. In this case, the assumption would still assert that infinite $(\RV{E}_i,\RV{X}_{i})$ sequences arising from observation would be interchangeable with infinite $(\RV{E}_j,\RV{X}_{j})$ sequences arising as consequences of actions, but because the $\RV{E}_i$ are never observed these interchanges do not imply that we would use the same model for different experiments.

To simplify the presentation, we will consider a specific kind of decision model featuring long sequence of exchangeable observations indexed by natural numbers that are unresponsive to the decision maker's choice and ``one more'' variable representing the ``consequences of action'' indexed by the special character $c$ that may be responsible ot the decision maker's choice. That is, we have $(\RV{X}_i)_{i\in \mathbb{N}}$ unresponsive to the decision maker and $(\RV{X}_c)$ responsive to the decision maker. Call this setup a ``see-do model''.

\begin{definition}[See-do model]
A see-do model is an decision model $(\prob{P}_\cdot,\Omega,C)$ along with a sequence of variables $\RV{X}_{\mathbb{N}\cup\{c\}}$ where $\RV{X}_{\mathbb{N}}\CI^e_{\prob{P}_\cdot} \mathrm{id}_C$. Variables indexed with $i\in \mathbb{N}$ are referred to as \emph{observations} and variables indexed with the special index $c$ are referred to as \emph{consequences}. We specify a see-do model with the shorthand $(\prob{P}_\cdot,\RV{X}_{\mathbb{N}\cup\{c\}})$.
\end{definition}

In this section, we will consider the following kind of ``standard'' see-do model: we have some observed variables $(\RV{X},\RV{Y},\RV{Z})$ and an unobserved variable $\RV{E}$ such that the observation pairs $(\RV{Z}_{i},(\RV{E}_i,\RV{X}_i,\RV{Y}_i))_{i\in \mathbb{N}}$ share conditionally independent and identical responses. Typically, this might be because we assume observations are exchangeable, but we also allow for cases where $\RV{Z}_i$ is not exchangeable -- for example, perhaps it is a time variable which monotonically increases. We also assume that the pairs $(\RV{E}_i,(\RV{X}_i,\RV{Y}_i))_{i\in\mathbb{N}\cup\{c\}}$ share conditionally independent and identical responses for all indices.

Recall that in Section \ref{sec:evaluating_decisions} we suggested that many systems might exhibit (probabilistically) regular input-output behaviours, but where we might not know or observe the right ``inputs''. The assumption that the pairs $(\RV{E}_i,(\RV{X}_i,\RV{Y}_i))_{i\in\mathbb{N}\cup\{c\}}$ share conditionally indpendent and identical responses can be viewed as a formalisation of this intuition; there is some unknown and unobserved state $\RV{E}_i$ which $\RV{X}_i$ and $\RV{Y}_i$ respond to in a regular manner no matter what else is happening.

Note that we make no assumptions about the distribution of $\RV{Z}_c$.

\begin{definition}[Latent CIIR see-do model]\label{def:lciirm}
A \emph{latent CIIR see-do model} is a see-do model $(\prob{P}_\cdot,(\RV{E}_i,\RV{Z}_{i},\RV{X}_i,\RV{Y}_i)_{i\in \mathbb{N}\cup\{c\}})$ such that the observation pairs $(\RV{Z}_{i},(\RV{E}_i,\RV{X}_i,\RV{Y}_i))_{i\in \mathbb{N}}$ share conditionally independent and identical responses and the pairs $(\RV{E}_i,(\RV{X}_i,\RV{Y}_i))_{i\in\mathbb{N}\cup\{c\}}$ also share conditionally independent and identical responses. We say the $\RV{E}_i$s are ``latent'' variables, which informally means that we typically do not get to observe them. We adopt the convention that the directing random conditional of $(\prob{P}_\cdot,\RV{Z}_{\mathbb{N}},(\RV{E}_i,\RV{X}_i,\RV{Y}_i)_{i\in \mathbb{N}})$.
\end{definition}

We can take any see-do model $(\prob{P}_\cdot,\RV{X}_{\mathbb{N}\cup\{c\}})$ with exchangeable observations and turn it into a latent CIIR see-do model by setting $\RV{Z}_i=*$ and $\RV{E}_i=(\RV{X}_i,\RV{Y}_i)$. This trivial construction typically isn't very helpful, though. One particular feature we might want is for a latent CIIR model to express the fact that ``things we can do have been done before''; that is, any setting of the unobserved state $\RV{E}_c$ that our actions might yield has positive probability in the observed data. Example \ref{ex:construction_latent_set} illustrates model constructions with and without this property.

\begin{example}\label{ex:construction_latent_set}
Suppose we have a see-do model $(\prob{P}_\cdot, \RV{X}_{\mathbb{N}\cup\{c\}})$ where each $\RV{X}_i$ takes values in a binary set, and the control we can exert is to choose either $\prob{P}_{0}^{\RV{X}_c} = \frac{1}{4}\delta_0 + \frac{3}{4}\delta_1$ or $\prob{P}_{1}^{\RV{X}-c} = \frac{1}{2}\delta_0 + \frac{1}{2}\delta_1$, independent of all other observations. Suppose further that for $i\in \mathbb{N}$, $\prob{P}_C^{\RV{X}_i}=\frac{3}{4}\delta_0 + \frac{1}{4}\delta_1$ independent of all other observations. Then we can consider this model to be IO contractible with latent binary inputs $\RV{E}_i$ such that
\begin{align}
	\prob{P}_\alpha^{\RV{X}_i|\RV{E}_i}(\cdot|e) &= \delta_e
\end{align}

This is not the only way to construct such a model. We could instead choose latent binary inputs $\RV{E}_i'$ such that
\begin{align}
	\prob{P}_\alpha^{\RV{X}_i|\RV{E}_i'}(\cdot|e) &= \begin{cases}
		\frac{3}{4}\delta_0 + \frac{1}{4}\delta_1 & e=0 \\
		\frac{1}{4}\delta_0 + \frac{3}{4}\delta_1 & e=1
	\end{cases}
\end{align}

On the other hand, the choice $\RV{E}_i^{\prime\prime}$ with
\begin{align}
	\prob{P}_\alpha^{\RV{X}_i|\RV{E}_i''}(\cdot|e) &= \begin{cases}
		\frac{1}{2}\delta_0 + \frac{1}{2}\delta_1 & e=0 \\
		\frac{1}{4}\delta_0 + \frac{3}{4}\delta_1 & e=1
	\end{cases}
\end{align}
cannot be latent binary inputs for a conditionally independent and identical response model, as the observational distribution cannot be written as any convex combination of $\prob{P}_\alpha^{\RV{X}_i|\RV{E}_i''}(\cdot|0)$ and $\prob{P}_\alpha^{\RV{X}_i|\RV{E}_i''}(\cdot|1)$.
\end{example}

In the first construction in Example \ref{ex:construction_latent_set}, but not the following two, we have $\prob{P}_C^{\RV{E}_i} \gg \prob{P}_\alpha^{\RV{E}_c}$ for all $\alpha$. We say under this construction the options have \emph{precedent}; they have, in a sense, ``been done before''. The assumption of precedent by itself has some implications -- for example, if a decision maker considers precedent a reasonable assumption and they have access to a lot of data, they they should not expect any of their actions to lead to consequences that have never appeared before in the observational data. In Theorem \ref{th:latent_to_observable}, we will make use a stronger version of this assumption where the conditional distribution over $\RV{E}_i$ is different for each value of $\RV{Z}_i$, which leads to stronger conclusions. We will discuss the plausibility of the stronger assumption afterwards.

Theorem \ref{th:latent_to_observable} is motivated by the following example:

\begin{example}\label{ex:doctor_precedent}
Suppose a decision maker collects data about a group of peope who have variously engaged the services of dietiticians, sporting coaches, general practitioners, bariatric surgeons and none of the above, with practitioner choice recorded under the variable $\RV{Z}_i$. The decision maker has also collected data on each person's body mass index $\RV{X}_i$ at the beginning of the study and followed mortality outcomes $\RV{Y}_i$ for a considerable period of time. A decision maker is reviewing this data, and in particular is wondering if steps they take to manage their weight $\RV{X}_c$ are likely to improve their own mortality prospects $\RV{Y}_c$.

Our decision maker presumes that each group of people $\RV{Z}_i$ has, in aggregate, different strategies for pursuing weight management and different contextual reasons for doing so (though, for the sake of this example, we suppose that the decision maker doesn't collect data on any of these facts). Because of this variation, the decison maker reasons, people in these different groups with different levels of body mass index should see different mortality results \emph{if, conditional on body mass index, the different circumstances and management strategies actually lead to different results}. Conversely, if there is \emph{no} variation in results for these different groups of people, then it would appear that, at least with regard to mortality, the eventual body mass index achieved is apparently the \emph{only} important feature of any management plan.

This inference might fail if, for any reason, the variation in treatment plans and contexts between the different groups of people surveyed masks the variation in their effects. For example, if all groups of people overwhelmingly choose to pursue diet changes in the end and other dimensions of variation are simply not very important to the outcome, then their results will not reveal any variation in mortality outcomes due to different treatment strategies. Alternatively, it might be the case that everybody is making choices that achieve nearly optimal mortality prospects given their unobserved context and that the best achievable mortality outcomes are approximately the same for each person's achievable level of body mass index. In this case there may still be substantial variation in outcomes from different weight management strategies, but it is masked by the fact that everyone is making near-optimal choices.

If the decision maker finds that $\RV{Y}_i$ is not independent of $\RV{Z}_i$ given $\RV{X}_i$, they may also consider whether $\RV{Y}_i$ is independent of $\RV{Z}_i$ given $(\RV{V}_i,\RV{X}_i)$ for some set of covariates $\RV{V}_i$.
\end{example}

Theorem \ref{th:latent_to_observable} establishes formal conditions for the informal deduction described in Example \ref{ex:doctor_precedent}. We assume that all variables of interest are discrete, and make use of an alternative notation for discrete conditional probabilities.

\begin{definition}[Index notation for discrete conditionals]
Given a joint probability distribution $\mu^{\RV{XY}}$ with $\RV{X}$ and $\RV{Y}$ discrete, let $\mu^y_x:=\mu^{\RV{Y}|\RV{X}}(\{y\}|x)$ and $\mu^Y_X:= (x,y)\mapsto \mu^y_x$
\end{definition}

The key assumption for Theorem \ref{th:latent_to_observable} is an assumption we call \emph{diverse precedent}. It's a rather complicated assumption. It imposes a domination condition that requires (roughly speaking) that the distribution of the latent input $\RV{E}_i$ given event $\RV{Z}_i=z$ almost surely dominates the distribution induced by any option we can choose (as in the discussion of precedent above) \emph{and} is almost surely ``diverse'' for different values of $\RV{Z}_i$.

\begin{definition}[Diverse precedent]\label{def:diverse_precedent}
Given a latent CIIR see-do model $(\prob{P}_\cdot,(\RV{E}_i,\RV{X}_i,\RV{Y}_i,\RV{Z}_i)_{i\in\mathbb{N}\cup\{c\}})$ with $E,X,Y$ and $Z$ all discrete, recall $\RV{G}$ is the directing random conditional of $(\prob{P}_\cdot,\RV{Z}_{\mathbb{N}},(\RV{E}_i,\RV{X}_i,\RV{Y}_i)_{i\in \mathbb{N}})$. 

We say that the options $C$ have \emph{diverse precedent} with respect to $(\prob{P}_\cdot,(\RV{E}_i,\RV{X}_i,\RV{Y}_i,\RV{Z}_i)_{i\in\mathbb{N}\cup\{c\}})$ if $\prob{P}_\cdot$ satisfies the diversity condition:
\begin{align}
    \prob{P}_{\alpha}^{\RV{G}^{EX}_{Z}|\RV{G}^{Y}_{EXZ}}(\cdot|g^{Y}_{EXZ}) &\ll U_{\Delta(E\times X)}& \forall \alpha, z, \prob{P}_\alpha-\text{almost all }g^{Y}_{EXZ}\label{eqApp:lebesgue_dom}
\end{align}
as well as the precedent condition:
\begin{align}
    \prob{P}_\alpha^{\RV{E}_c|\RV{G}} &\ll \sum_{z\in Z}\prob{P}_\alpha^{\RV{E}_i|\RV{G}}(\cdot|g)&\prob{P}_\alpha-\text{almost all }g
\end{align}
Where $U_{\Delta(E)}$ is the uniform measure on the $|E-1|$ simplex of discrete probability distributions with $|E|$ outcomes.
\end{definition}

For Theorem \ref{th:latent_to_observable}, we assume that on the basis of observations we condition the probability on some event $I$ (in particular, we are interested in the case where $I$ is the event that a certain conditional independence holds).

\begin{theorem}[Latent to observable IO contractibility]\label{th:latent_to_observable}
Given a latent CIIR see-do model $(\prob{P}_\cdot,(\RV{E}_i,\RV{X}_i,\RV{Y}_i,\RV{Z}_i)_{i\in\mathbb{N}\cup\{c\}})$ with $E,X,Y$ and $Z$ all discrete, recall $\RV{G}$ is the directing random conditional of $(\prob{P}_\cdot,\RV{Z}_{\mathbb{N}},(\RV{E}_i,\RV{X}_i,\RV{Y}_i)_{i\in \mathbb{N}})$.

Let $I\subset \Delta(Y)^{XZ}$ be the event $\RV{G}^Y_{Xz}=\RV{G}^Y_{Xz'}$ for all $z,z'\in Z$; i.e. the event that $\RV{Y}_i$ is independent of $\RV{Z}_i$ conditional on $\RV{X}_i$ and $\RV{G}^Y_{XZ}$. Define $\prob{Q}_\alpha\in \Delta(\Omega)$ to be the probability measure such that, for all $A\in \sigalg{F}$
\begin{align}
\prob{Q}_\alpha(A) := \prob{P}_\alpha^{\mathrm{id}_\Omega|\mathds{1}_I\circ \RV{G}}(A|1)
\end{align}
i.e. $\prob{Q}_\alpha$ is $\prob{P}_\alpha$ conditioned on $\RV{G}^Y_{XZ}\in I$, so $\RV{Y}_i\CI^e_{\prob{Q}_\cdot} \RV{Z}_i|(\RV{X}_i,\mathrm{id}_C)$.

If the options $C$ have diverse precedent with respect to $(\prob{Q}_\cdot,(\RV{E}_i,\RV{X}_i,\RV{Y}_i,\RV{Z}_i)_{i\in\mathbb{N}\cup\{c\}})$, then the model $(\prob{Q}_\cdot,\RV{X},\RV{Y})$ features conditionally independent and identical responses $(\RV{X}_i,\RV{Y}_i)$.
\end{theorem}

\begin{proof}
We show that the assumption of conditional independence imposes a polynomial constraint on $\RV{G}^d_z$ which is nontrivial unless $\RV{Y}_i\CI^e (\RV{Z}_i,\RV{E}_i,\text{id}_C)|(\RV{X}_i,\RV{H})$, and hence the solution set $S$ for this constraint has measure 0 when this conditional independence does not hold.

Full proof in Appendix \ref{sec:proof_precedent}.
\end{proof}

<<<<<<< HEAD
\section[Independent mechanisms]{Diversity, interventional models and the principle of independent causal mechanisms}

In this section we will present an informal argument that connects the principal of \emph{diversity} (Def. \ref{def:diverse_precedent}) to a particular family of structural interventional models via the principle of independent causal mechanisms.

As we have already mentioned ``precedent'' part of Definition \ref{def:diverse_precedent} can be intepreted as the assumption that whatever the decision maker can do has been done before. It is more likely to be acceptable when the actions the decision maker is considering are common -- such as controlling body mass index by adopting a widely known diet -- and less likely to be acceptable when the decision maker is considering uncommon actions like controlling body mass index by removing limbs. It is less obvious what considerations might lead one to accept or reject the diversity condition.

To better understand this, we note that Theorem \ref{th:latent_to_observable} can be informally summarised as follows:
\begin{itemize}
	\item If $\RV{Y}_i\CI^e_\prob{Q} \RV{Z}_i |(\RV{X}_i,\RV{G},\mathrm{id}_C)$ then we must either have ``alignment'' between $\RV{G}^{XE}_Z$ and $\RV{G}^{Y}_{EXZ}$ or we also have $\RV{Y}_i\CI^e_\prob{Q} \RV{E}_i |(\RV{X}_i,\RV{G},\mathrm{id}_C)$
	\item If we assume diversity of $\RV{G}^{XE}_Z$ conditioned on $\RV{G}^{Y}_{EXZ}$ -- i.e. we rule out ``alignment'' -- then we must conclude $\RV{Y}_i\CI^e_\prob{Q} \RV{E}_i |(\RV{X}_i,\RV{G},\mathrm{id}_C)$
\end{itemize}

What we mean by ``alignment'' here is that $\RV{G}^{XE}_Z$ is restricted to some particular set of Lebesgue measure 0 conditioned on $\RV{G}^{Y}_{EXZ}$ in order to yield the independence $\RV{Y}_i\CI^e_\prob{Q} \RV{Z}_i |(\RV{X}_i,\RV{G},\mathrm{id}_C)$. ``Alignment'' of this form might seem like it would usually be unlikely, but this is not necessarily so. However, there are several reasons not to assume that the diversity condition is satisfied in general. 

First, we require diversity to be satisfied \emph{after} observing $\RV{Y}_i\CI^e_\prob{Q} \RV{Z}_i |(\RV{X}_i,\RV{G},\mathrm{id}_C)$. If we accept diversity in this context, then we conclude $\RV{Y}_i\CI^e_\prob{Q} \RV{E}_i |(\RV{X}_i, \RV{Z}_i, \RV{G},\mathrm{id}_C)$, which is \emph{also} a Lebesgue measure 0 event with respect to $\Delta(Y)^{EXZ}$. Thus it's not enough to assume that violations of diversity are unlikely in general -- we have to assume that they are less likely than the conditional independence $\RV{Y}_i\CI^e_\prob{Q} \RV{E}_i |(\RV{X}_i, \RV{Z}_i, \RV{G},\mathrm{id}_C)$.

Second, some violations of diversity may be relatively plausible. For example, the independence $\RV{E}_i\CI^e_\prob{Q} \RV{Z}_i |(\RV{G},\mathrm{id}_C)$ is a violation of diversity, but the unconditional independence of two variables is not, in general, an implausible event.

Third, the \emph{principal of independent causal mechanisms} (ICM) offers another possible way for the assumption of diversity to fail\citep{lemeire_replacing_2013,peters_elements_2017}. ICM is an informal principle that posits conditionals like $\RV{G}^{XE}_Z$ and $\RV{G}^{Y}_{EXZ}$ will be ``independent'' or ``unaligned'' under structural causal assumptions that identify both of these conditionals as ``causal mechanisms''. Conversely, it is argued (for example in \citet[Ch. ~2]{peters_elements_2017}) that conditionals that do not correspond to ``causal mechanisms'' may exhibit ``alignment'' of the kind we have discussed here.

The first of these reasons is a general caution against assuming diversity too readily in any situation. The second and third are two different ways that the diversity condition could fail. In fact, both of these failures of diversity can be illustrated with a particular family of graphical causal models.

\subsection{Graphical models and causal mechanisms}

A graphical causal model is defined in \citet[Ch. ~1]{pearl_causality:_2009} as a large collection of \emph{interventional conditionals} which can be compactly encoded with a probability distribution over a collection of variables together with a graph associated with these variables (see Definition \ref{def:vga}). We will consider a slightly different variety of graphical model; we will consider a \emph{graphical ciir model} to be a directed acyclic graph $\mathcal{G}$ associated with a latent CIIR model (Definition \ref{def:lciirm}) instead of a collection of interventional conditionals.

\begin{definition}[Graphical CIIR model]
A graphical CIIR model is a latent CIIR model $(\prob{P}_\cdot,(\RV{E}_i,\RV{Z}_{i},\RV{X}_i,\RV{Y}_i)_{i\in \mathbb{N}\cup\{c\}})$ along with a collection of directed acyclic graphs $\mathscr{G}:=\{\mathcal{G}_i|i\in A\subset\mathbb{N}\}$ associated with $(\RV{E}_c, \RV{Z}_c,\RV{X}_c,\RV{Y}_c)$.
\end{definition}

A \emph{causal mechanism} in a graphical CIIR model is a conditional distribution associated with a parental set in the associated graph $\mathcal{G}$.

\begin{definition}[Causal mechanism]
Given a CIIR model $(\prob{P}_\cdot,(\RV{E}_i,\RV{Z}_{i},\RV{X}_i,\RV{Y}_i)_{i\in \mathbb{N}\cup\{c\}})$ along with an associated graph $\mathcal{G}$, a \emph{causal mechanism} is a conditional distribution $\RV{G}^{V}_{\mathrm{Pa}_{\mathcal{G}}(\RV{V})}$ for any $V\in \{\RV{E}_c,\RV{Z}_c,\RV{X}_c,\RV{Y}_c\}$.
\end{definition}

We hold that every graph in a graphical CIIR model is associated with an event. We can condition on the event associated with $\mathcal{G}_i$ to yield the model that would obtain ``if we knew $\mathcal{G}_i$ were the correct caual graph''. We require that the model conditioned on a graph $\mathcal{G}_i$ is \emph{compatible} with this graph -- which reflects the common prescription that a probability distribution should be \emph{compatible} with an associated causal graph $\mathcal{G}$\citet[Ch. ~1]{pearl_causality:_2009} -- and we \emph{also} require that, after conditioning on a graph, the causal mechanisms in the graph are \emph{mutually diverse}. This is a formalisation of the principal of independent causal mechanisms. We treat graphs as conditioning events to reflect the fact that we do not necessarily know \emph{a priori} whether or not this compatibility holds for any given graph.

\begin{definition}[Conditioning on a graph]
We will assume that each graph $\mathcal{G}_i\in \mathscr{G}$ describes a conditioning event for the associated CIIR model $(\prob{P}_\cdot,(\RV{E}_i,\RV{Z}_{i},\RV{X}_i,\RV{Y}_i)_{i\in \mathbb{N}\cup\{c\}})$ such that, letting $\prob{P}_{\cdot,i}$ be the result of conditioning $\prob{P}_\cdot$ on the event associated with $\mathcal{G}_i$, we have:
\begin{enumerate}
	\item $V_j\perp_{\mathcal{G}} V_k|\RV{V}_l$ for $V_j,V_k,V_l\in \{E_c,Z_c,X_c,Y_c\}$ implies $\RV{V}_j\CI^e_{\prob{P}_{\cdot,i}} \RV{V}_k |(\RV{V}_l,\RV{G},\mathrm{Id}_C)$
	\item $\prob{P}_{\alpha,i}^{\RV{G}^{V_j}_{\mathrm{Pa}_{\mathcal{G}_i}(V_j)}|(\RV{G}^{V_k}_{\mathrm{Pa}_{\mathcal{G}_i}}(V_k))_{k\neq j}}(\cdot|(g^{V_k}_{\mathrm{Pa}_{\mathcal{G}_i}(V_k)})_{k\neq j}) \ll U_{\Delta(V_j)}$ for all $\alpha, z$ and $\prob{P}_\alpha$-almost all $(g^{V_k}_{\mathrm{Pa}_{\mathcal{G}_i}(V_k)})_{k\neq j}$
\end{enumerate}
\end{definition}

=======
\section{Continuity and discovery}{Causal discovery and the absolute continuity assumption}

We've suggested that the precedent assumption may be plausible when we suppose that the outcomes of interest exhibit a probabilistically regular response to some unobserved state, and that the values of this unobserved state that can be brought about through our actions have some precedent in the observed data. The continuity assumption deserves some more attention. Note that we require the continuity assumption to hold after conditioning on the independence of $\RV{Y}_i$ from $\RV{Z}_i$ given $\RV{X}_i$; the core of Theorem \ref{th:latent_to_observable} is that if we rule out the possibility of explaining this independence through a lack of ``continuity'' of the conditionals $\RV{G}^{X}_{EZ}$ and $\RV{G}^{E}_{Z}$, then it must be due to $\RV{Y}_i$ also being independent of $\RV{E}_i$ given $\RV{X}_i$. Under what circumstances would we want to rule out explaining this independence through a lack of continuity?

We do not propose a conclusive answer to this question. However, the causal discovery literature offers a possible approach which we will explain here. Causal structures have two useful properties for this purpose: first, they can ``explain'' conditional independences like $\RV{Y}_i$ is independent of $\RV{Z}_i$ given $\RV{X}_i$. Second, under standard interpretations, given a structural causal model, parental conditional probabilities are mutually continuous (in our terminology). This property has been noted before, and has been informally stated as the \emph{principle of independent causal mechanisms} (in spite of the name, parental conditional probabilities need not be probabilistically independent) \citep{lemeire_replacing_2013,peters_elements_2017}.

To illustrate why we need to explain the conditional independence, suppose we pick a ``prior'' distribution of $\RV{G}^{EXY}_{Z}$ (by which we just mean $\prob{P}_{\cdot}^{\RV{G}^{EXY}_{Z}}$) such that for each $z,z'\in Z$, the distribution of $\RV{G}^{EXY}_z$ conditional on $\RV{G}^{EXY}_{z'}$ is absolutely continuous with respect to the uniform measure on $E\times X\times Y$. In this case, the event $\RV{G}^Y_{Xz}=\RV{G}^Y_{Xz'}$ would have probability 0 for all $z,z'\in Z$. As such, this ``prior'' does not tell us whether diverse precedent holds after conditioning on this event, as conditional probabilities are not determined by the joint distribution on measure 0 events. Thus this prior does not tell us whether diverse precedent holds after conditioning on the independence of $\RV{Y}_i$ from $\RV{Z}_i$ given $\RV{X}_i$.

Bayesian causal discovery approaches prior specification in a different way. This approach considers a mixture of graphical hypotheses which each imply certain conditional independences \citep{heckerman_learning_1995}. Because each graphical hypothesis is given positive probability, independences like $\RV{Y}_i$ independent of $\RV{Z}_i$ given $\RV{X}_i$ also have positive probability, in contrast with the approach that sets $\RV{G}^{EXY}_z$ absolutely continuous with respect to the uniform measure.

Another conventional feature of structure learning is the assumption that the parameters associated with parental conditional distributions are mutually continuous. That is, for any $\RV{X}$, fixing a hypothesised structure $\mathcal{G}$, $\prob{P}_\cdot^{\RV{G}^{X}_{\mathrm{Pa}_\mathcal{G}(X)}|\RV{G}^{X^\complement}_{\mathrm{Pa}_\mathcal{G}(X^\complement)}}$ is absolutely continuous (see Definition \ref{def:mga} for the meaning of $\mathrm{Pa}_{\mathcal{G}}(\RV{X})$). \citep{heckerman_learning_1995} assumes these parameters are mutually independent with absolutely continuous marginals. While not explicitly Bayesian, \citet{meek_strong_1995} argues that given a hypothesised causal model, \emph{unfaithful}\footnote{See the referenced paper for a definition.} distributions are unlikely because they violate mutual absolute continuity.

Putting these properties together, we have:
\begin{itemize}
	\item We may ``explain'' the independence $\RV{Y}_i\CI^e_{\prob{Q}} \RV{Z}_i | (\RV{G}, \mathrm{id}_C)$ with a hypothesised causal structure $\mathcal{G}$
	\item If \emph{either} $\RV{Z}_i$ is a parent of $\RV{E}_i$ or $\RV{E}_i$ and $\RV{Z}_i$ are parents of $\RV{X}_i$ in $\mathcal{G}$ then the relevant continuity property for Theorem \ref{th:latent_to_observable} holds
\end{itemize}
>>>>>>> 0d35ed3e099926a4a263bdae7d9805af4b6d5e15

For example, suppose we consider a class of structural hypotheses $\mathcal{G}_i$ where, in all structures, we have $\RV{E}_i\rightarrowtriangle \RV{X}_i$ and $\RV{G}_i\rightarrowtriangle \RV{X}_i$. One such structure is illustrated below:

\begin{align}
	\mathcal{G}_1 := \tikzfig{structural_model_1} \label{eq:structural_model_1}
\end{align}
<<<<<<< HEAD
We note in this graph that $\mathrm{Pa}_{\mathcal{G}}(\RV{E},\RV{X})=\RV{Z}$ and $\mathrm{Pa}_{\mathcal{G}}(\RV{Y})=\RV{X}$
\end{example}

, a ``causal mechanism'' is a conditional distribution $\RV{G}^{X}_{\mathrm{Pa}_{\mathcal{G}}(X)}$.

\emph{Causal discovery} refers to a variety of strategies that aim to infer a causal structure from a set of observations. A common approach to causal discovery is to learn the causal structures that are faithful to the conditional independence structure of the observed data. We can use this approach to causal discovery to motivate the assumption of diversity as follows:
\begin{itemize}
	\item Begin with a set of possible causal structures $\mathscr{G}$
	\item ``Observe'' $\RV{Y}_i\CI^e_\prob{Q} \RV{Z}_i |(\RV{X}_i,\RV{G},\mathrm{id}_C)$ and retain the subset $\mathscr{G}'$ faithful to this conditional indepdenence
	\item Check whether $\RV{G}^{XE}_Z$ and $\RV{G}^{Y}_{EXZ}$ are independent causal mechanisms in the resulting set of causal structures
\end{itemize}




=======
>>>>>>> 0d35ed3e099926a4a263bdae7d9805af4b6d5e15

In $\mathcal{G}_1$ (and, indeed, in every $\mathcal{G}_i$) we have $\mathrm{Pa}_{\mathcal{G}_i}(\RV{X}_i)=(\RV{Z}_i,\RV{E}_i)$. Furthermore, $\RV{G}^E_Z$ is determined by $\RV{G}^E$ and $\RV{G}^Z_E$, which are both parental parameters in $\mathcal{G}_1$ and therefore mutually absolutely continuous with $\RV{G}^X_{EZ}$. Finally, $\RV{G}^Y_{EXz} = \RV{G}^Y_{EX}$ for all $z\in Z$ is also a parental conditional and therefore also mutually absolutely continuous with $\RV{G}^X_{EZ}$. Thus, given hypothesis $\mathcal{G}_1$, if we also accept the assumption of precedent, Theorem \ref{th:latent_to_observable} follows. In fact, we can similarly argue that Theorem \ref{th:latent_to_observable} follows for all structures $\mathcal{G}_i$ where:
\begin{itemize}
	\item $\RV{E}_i\rightarrowtriangle \RV{X}_i$ and $\RV{Z}_i\rightarrowtriangle \RV{X}_i$
	\item $\RV{E}_i\rightarrowtriange \RV{X}_i$ and $\RV{Z}_i\rightarrowtriangle \RV{E}_i$
\end{itemize}

On the other hand, consider
\begin{align}
	\mathcal{G}_2 := \tikzfig{structural_model_2} \label{eq:structural_model_2}
\end{align}

Here we also have $\RV{Y}_i\CI^e_{\prob{Q}} \RV{Z}_i | (\RV{G}, \mathrm{id}_C)$, but absolute continuity is not obviously supported; neither $\RV{G}^X_{EZ}$ nor $\RV{G}^E_Z$ are parental parameters. In fact, we can observe that in $\mathcal{G}_2$ we have $\RV{Y}_i\CI^e_{\prob{Q}} \RV{Z}_i | (\RV{X}_i, \RV{G}, \mathrm{id}_C)$ given an arbitrary choice of $\RV{G}^Y_{EX}$, but not $\RV{Y}_i\CI^e_{\prob{Q}} \RV{E}_i | (\RV{X}_i, \RV{G}, \mathrm{id}_C)$, so by the contrapositive of Theorem \ref{th:latent_to_observable} we must not have the relevant absolutely continuous conditionals.

If, in our original example, instead of conditioning on medical practitioners, we take $\RV{Z}_i$ to be an individual's clothing size and (for the sake of argument) find the same result: mortality outcomes $\RV{Y}_i$ are independent of clothing size $\RV{Z}_i$ conditional on body mass index $\RV{X}_i$. There are no doubt some differences between people with the same body mass index who wear differently sized clothes -- height, for example -- but it is not clear from the given data whether we should conclude that any common actions affecting a person's health do so via their body mass index, or whether there are features relevant to a person's health that fail to be correlated with clothing size after conditioning on body mass index. This example is motivated by structure \eqref{eq:structural_model_2}, though it's hard to come up with an example that is inarguably an instance of this structure and also not excessively convoluted.


While we've argued that structure \eqref{eq:structural_model_1} implies $\RV{Y}_i \CI^e_{\prob{P}} \RV{E}_i | (\RV{X}_i, \mathcal{G}_1, \RV{G}, \mathrm{id}_C)$ via Theorem \ref{th:latent_to_observable}, we can note that it also implies this independence via d-separation. On the other hand, \eqref{eq:structural_model_2} does not imply such a conditional independence via Theorem \ref{th:latent_to_observable} or via d-separation. This correspondence is not exact - the structure \eqref{eq:structural_model_3} implies $\RV{Y}_i \CI^e_{\prob{P}} \RV{E}_i | (\RV{X}_i, \mathcal{G}, \RV{G}, \mathrm{id}_C)$ via d-separation, but not via Theorem \ref{th:latent_to_observable}. The existence of such stuctures may not be especially surprising, given that Theorem \ref{th:latent_to_observable} establishes sufficient but not necessary conditions.

\begin{align}
	\mathcal{G}_2 := \tikzfig{structural_model_3} \label{eq:structural_model_3}
\end{align}

The alternative d-separation criterion does uphold the general rule we observed, where $\RV{E}_i\rightarrowtriangle \RV{X}_i$ and $\RV{Z}_i\rightarrowtriangle \RV{X}_i$ or $\RV{E}_i\rightarrowtriange \RV{X}_i$ and $\RV{Z}_i\rightarrowtriangle \RV{E}_i$ are sufficient to establish $\RV{Y}_i \CI^e_{\prob{P}} \RV{E}_i | (\RV{X}_i, \mathcal{G}_i, \RV{G}, \mathrm{id}_C)$, while the absence of either of these edges is compatible with structures that do not imply the relevant independence.

If we assume structural models are expressing the assumption that parental conditional probabilities are mutually absolutely continuous, it may be the case that d-separation properties capture all interesting consequences like those of Theorem \ref{th:latent_to_observable} where mutual absolute continuity supports additional conditional independence implications. It is well known that conditional independences relationships not implied by a structure $\mathcal{G}$ can be broken by choosing slightly different parental conditionals (see for example \citet{meek_strong_1995,zhang_strong_2003}), thus under the assumption that all parental conditionals relative to a structure $\mathcal{G}$ are mutually absolutely continuous we would not find additional conditional independence properties. We may wonder if there are interesting mutual absolute continuity assumptions that are not representable as a directed acyclic graph. In fact, the conditions for Theorem \ref{th:latent_to_observable} are somewhat weaker than those expressed by a structural model -- it only assumes mutual absolute continuity for a subset of conditionals, whereas a structural model assigns every variable a parental set and implies the mutual absolute continuity of every parental conditionals. However, as we have argued, this difference does not seem to matter in this case as both approaches yield the same conclusion.

In this discussion, we have suggested that structural causal models may play a role informing judgements of mutual absolute continuity. While this is a standard feature of the interpretation of structural causal models -- and \citet{lemeire_replacing_2013} has proposed that this idea should play a critical role in our understanding of causal structures -- for the purposes of assessing consequences of actions, the interpretation of causal models as ``interventional oracles'' \citep[Section 1.3.1]{pearl_causality:_2009} is usually given prominence. Here, we consider precedent as an alternative to the assumption of structural interventions, and lean on the interpretation of mutual absolute continuity to derive nontrivial conclusions.

\section{Conclusion}

We employ a decision theoretic approach to causal inference to investigate two different approaches to answering the question ``how do my observations relate to the consequences of my choices?''. Firstly, we examined the assumption of conditionally independent and identical responses, and its equivalent form in IO contractibility, which we argued was often an unreasonable assumption and secondly, we examined an approach based on the principle of precedent, or the idea that the decision maker's options have been taken before, and some of their consequences observed. Our approach allows us to consider the question of what observations and consequences have in common independently from any prior knowledge the decision maker might have about how their choices influence outcomes -- neither Theorem \ref{th:ciid_rep_kernel} nor Theorem \ref{th:latent_to_observable} depend on any assumptions about a decision maker's prior knowledge of the effects of their different options (though the plausibility of the assumptions in both theorems may well depend on such prior knowledge).

The grand aim of this work is to facilitate causal inference in situations where a decision maker has relatively little causal knowledge at the outset. We think avoiding structured interventions in this setting is advantageous because we regard the question of whether an action is known in advance to influence a particular variable as substantially more transparent than the question of whether it is well modeled by a structured intervention (of any type) on that variable.

Nevertheless, this work leaves many open questions for causal inference in the low prior knowledge setting. We have argued that the assumptions required for Theorem \ref{th:ciid_rep_kernel} are unlikely to be compelling in many situations. While the diverse precedent assumption may be more broadly plausible, it is at this stage difficult to evaluate. Speculatively, it may be possible to make progress on this question by better understanding when structural assumptions support this conclusion, via for example the causal version of the principle of maximum entropy.

For practical purposes, a generalisation of Theorem \ref{th:latent_to_observable} to approximate independence is in order, and such a generalisation may also bring additional clarity to the diverse precedent assumption.

Despite these challenges, we are encouraged by a number of features of this work. Using decision making as a starting point for constructing models means that, at the outset, we are only making commitments a decision maker is likely to already be making if they want to apply a formal theory of decision making. The informal idea of precedent that underpins Theorem \ref{th:latent_to_observable} seems like a general principle that may be applicable in a broad range of data-driven decision making problems. Finally, the apparent connection between Theorem \ref{th:latent_to_observable} suggests that much of the work already done in the world of causal graphical models may be applicable to our alternative perspective. Causal inference under circumstances of limited prior knowledge presents many hard conceptual as well as practical problems, and our approach is a promising new avenue of investigation.

